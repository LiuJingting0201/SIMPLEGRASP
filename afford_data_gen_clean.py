# -*- coding: utf-8 -*-
"""
è‡ªç›‘ç£æŠ“å–å¯ä¾›æ€§æ•°æ®ç”Ÿæˆå™¨ v3 - æ¸…ç†ç‰ˆ
Self-supervised Grasp Affordance Data Generator

ç®€å•    if visualize:
        print(f"   ğŸ“ æ¡Œé¢æ·±åº¦: {table_depth:.3f}m (ç›´æ–¹å›¾å³°å€¼)")
        print(f"   ğŸ“ ç‰©ä½“é˜ˆå€¼: < {depth_threshold:.3f}m (æ¯”æ¡Œé¢è¿‘10mm+)")
        print(f"   ğŸ¯ æ·±åº¦æ£€æµ‹: {depth_based_objects.sum()} åƒç´  ({100*depth_based_objects.sum()/(height*width):.1f}%)")1. ç”¨RGBæ ‡å‡†å·®æ‰¾å½©è‰²ç‰©ä½“
2. ä½¿ç”¨è¿™äº›åƒç´ çš„æ·±åº¦å€¼
3. ç”ŸæˆæŠ“å–å€™é€‰å¹¶æµ‹è¯•
"""

import pybullet as p
import numpy as np
import time
import json
import os
from pathlib import Path
import cv2
import argparse

from environment_setup import setup_environment
from perception import set_topdown_camera, get_rgb_depth, get_rgb_depth_segmentation, pixel_to_world, CAMERA_PARAMS


# ==================== é…ç½®å‚æ•° ====================

DATA_DIR = Path(__file__).parent.parent / "data" / "affordance_v4"
NUM_ANGLES = 16
ANGLE_BINS = np.linspace(0, np.pi, NUM_ANGLES, endpoint=False)

# é‡‡æ ·å‚æ•°
FOREGROUND_STRIDE = 8
BACKGROUND_STRIDE = 64
MIN_DEPTH = 0.01
COLOR_DIFF_THRESHOLD = 30  # é¢œè‰²å·®å¼‚é˜ˆå€¼ï¼šä¸æ¡Œå­é¢œè‰²çš„è·ç¦»ï¼ˆè¶Šå¤§è¶Šä¸¥æ ¼ï¼‰
EDGE_MARGIN = 20  # ä»å›¾åƒè¾¹ç¼˜é‡‡æ ·æ¡Œå­é¢œè‰²çš„è¾¹è·ï¼ˆåƒç´ ï¼‰

# æŠ“å–å‚æ•°
TABLE_TOP_Z = 0.625
PRE_GRASP_OFFSET = 0.12  # é¢„æŠ“å–é«˜åº¦ï¼ˆä»ç‰©ä½“é¡¶éƒ¨ï¼‰
GRASP_OFFSET = -0.01    # æŠ“å–é«˜åº¦ï¼šç‰©ä½“é¡¶éƒ¨ä¸‹æ–¹5mmï¼ˆè¿›å…¥ç‰©ä½“ä»¥æŠ“å–ï¼‰
POST_GRASP_OFFSET = 0.00
LIFT_HEIGHT = 0.30
GRIPPER_CLOSED = 0.00
FAST_STEPS = 120
SLOW_STEPS = 600


def create_data_dirs():
    """åˆ›å»ºæ•°æ®ç›®å½•"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR.absolute()}")


def sample_grasp_candidates(depth, num_angles=NUM_ANGLES, visualize=False, rgb=None, view_matrix=None, proj_matrix=None, seg_mask=None, object_ids=None):
    """åŸºäºPyBullet segmentation maskçš„ç‰©ä½“åˆ†å‰²ç­–ç•¥"""
    height, width = depth.shape
    candidates = []
    
    if seg_mask is None or object_ids is None:
        print(f"   âš ï¸  éœ€è¦segmentation maskå’Œobject IDs")
        return candidates
    
    # âœ¨ å…³é”®ä¿®å¤ï¼šé¦–å…ˆæ£€æŸ¥æ˜¯å¦çœŸçš„æœ‰ç‰©ä½“å­˜åœ¨
    if len(object_ids) == 0:
        print(f"   âš ï¸  ç‰©ä½“åˆ—è¡¨ä¸ºç©ºï¼Œæ— å€™é€‰ç‚¹")
        return candidates
    
    # Step 1: ä½¿ç”¨PyBullet segmentation maskç›´æ¥è·å–ç‰©ä½“åƒç´   
    object_mask = np.zeros((height, width), dtype=bool)
    valid_object_count = 0
    
    for obj_id in object_ids:
        try:
            # éªŒè¯ç‰©ä½“æ˜¯å¦çœŸçš„å­˜åœ¨äºåœºæ™¯ä¸­
            pos, _ = p.getBasePositionAndOrientation(obj_id)
            obj_pixels = (seg_mask == obj_id)
            if obj_pixels.sum() > 0:  # åªæœ‰åœ¨ç›¸æœºä¸­å¯è§çš„ç‰©ä½“æ‰è®¡ç®—
                object_mask |= obj_pixels
                valid_object_count += 1
                if visualize:
                    print(f"      ç‰©ä½“ ID={obj_id}: {obj_pixels.sum()} åƒç´ , ä½ç½®=[{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}]")
        except:
            # ç‰©ä½“ä¸å­˜åœ¨
            if visualize:
                print(f"      ç‰©ä½“ ID={obj_id}: ä¸å­˜åœ¨")
            continue
    
    # âœ¨ å…³é”®ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰æœ‰æ•ˆç‰©ä½“åƒç´ ï¼Œè¿”å›ç©ºåˆ—è¡¨
    if valid_object_count == 0 or object_mask.sum() == 0:
        print(f"   âš ï¸  æœªæ£€æµ‹åˆ°æœ‰æ•ˆç‰©ä½“ (æœ‰æ•ˆç‰©ä½“æ•°: {valid_object_count}, åƒç´ æ•°: {object_mask.sum()})")
        return candidates
    
    # è¿‡æ»¤æ‰æ·±åº¦æ— æ•ˆçš„åƒç´ 
    object_mask &= (depth > MIN_DEPTH)
    
    if visualize:
        print(f"   ğŸ¯ Segmentationæ£€æµ‹: {object_mask.sum()} åƒç´  ({100*object_mask.sum()/(height*width):.1f}%)")
        print(f"   ğŸ¯ æœ‰æ•ˆç‰©ä½“æ•°: {valid_object_count}")
        
        # æ˜¾ç¤ºç‰©ä½“æ·±åº¦ç»Ÿè®¡
        if object_mask.sum() > 0:
            obj_depths = depth[object_mask]
            valid_obj_depths = obj_depths[obj_depths > MIN_DEPTH]
            if len(valid_obj_depths) > 0:
                print(f"   ğŸ“Š ç‰©ä½“æ·±åº¦: min={valid_obj_depths.min():.3f}m, max={valid_obj_depths.max():.3f}m, mean={valid_obj_depths.mean():.3f}m")
    
    # âœ¨ å†æ¬¡æ£€æŸ¥ï¼šå¦‚æœè¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆåƒç´ ï¼Œè¿”å›ç©º
    if object_mask.sum() == 0:
        print(f"   âš ï¸  è¿‡æ»¤åæ— æœ‰æ•ˆç‰©ä½“åƒç´ ")
        return candidates
    
    print(f"   ğŸ¯ æ£€æµ‹åˆ°ç‰©ä½“åƒç´ : {object_mask.sum()}")
    
    # Step 3: åœ¨ç‰©ä½“åŒºåŸŸé‡‡æ ·
    # å¯¹äºå°ç‰©ä½“ï¼ˆ< 100åƒç´ ï¼‰ï¼Œç›´æ¥åœ¨æ‰€æœ‰åƒç´ ä¸Šé‡‡æ ·ï¼Œä¸erode
    if object_mask.sum() < 100:
        print(f"   ğŸ¯ å°ç‰©ä½“ï¼šç›´æ¥é‡‡æ ·æ‰€æœ‰åƒç´ ")
        # è·å–æ‰€æœ‰ç‰©ä½“åƒç´ 
        obj_coords = np.where(object_mask)
        obj_center_v = int(np.mean(obj_coords[0]))
        obj_center_u = int(np.mean(obj_coords[1]))
        
        # å¯¹æ¯ä¸ªç‰©ä½“åƒç´ ï¼ŒæŒ‰è·ç¦»ä¸­å¿ƒæ’åº
        positions = []
        for i in range(len(obj_coords[0])):
            v, u = obj_coords[0][i], obj_coords[1][i]
            dist = (u - obj_center_u)**2 + (v - obj_center_v)**2
            positions.append((dist, u, v))
        
        positions.sort()
        
        # ä¸ºæ¯ä¸ªåƒç´ æ·»åŠ æ‰€æœ‰è§’åº¦çš„å€™é€‰
        for theta_idx in range(num_angles):
            theta = ANGLE_BINS[theta_idx]
            for dist, u, v in positions:
                candidates.append((u, v, theta_idx, theta))
    else:
        # å¤§ç‰©ä½“ï¼šä½¿ç”¨erosionæ‰¾åˆ°ä¸­å¿ƒåŒºåŸŸ
        kernel = np.ones((5, 5), np.uint8)
        eroded = cv2.erode(object_mask.astype(np.uint8), kernel, iterations=2)
        
        if eroded.sum() > 0:
            print(f"   ğŸ¯ ç‰©ä½“ä¸­å¿ƒ: {eroded.sum()} åƒç´ ")
            # ä¸­å¿ƒåŒºåŸŸ
            coords = np.where(eroded > 0)
            center_v = int(np.mean(coords[0]))
            center_u = int(np.mean(coords[1]))
            
            positions = []
            for v in range(0, height, 4):
                for u in range(0, width, 4):
                    if eroded[v, u]:
                        dist = (u - center_u)**2 + (v - center_v)**2
                        positions.append((dist, u, v))
            
            positions.sort()
            
            # æ·»åŠ å€™é€‰ï¼ˆä¸åŒè§’åº¦ï¼‰
            for theta_idx in range(num_angles):
                theta = ANGLE_BINS[theta_idx]
                for dist, u, v in positions:
                    candidates.append((u, v, theta_idx, theta))
        
        # è¾¹ç¼˜åŒºåŸŸ
        edge = object_mask & (~eroded.astype(bool))
        if edge.sum() > 0:
            edge_pos = []
            for v in range(0, height, FOREGROUND_STRIDE):
                for u in range(0, width, FOREGROUND_STRIDE):
                    if edge[v, u]:
                        edge_pos.append((u, v))
            
            for theta_idx in [0, 4, 8, 12]:
                if theta_idx < num_angles:
                    theta = ANGLE_BINS[theta_idx]
                    for u, v in edge_pos:
                        candidates.append((u, v, theta_idx, theta))
    
    # âœ¨ å…³é”®ä¿®å¤ï¼šåªæœ‰å½“æœ‰ç‰©ä½“æ—¶æ‰æ·»åŠ å°‘é‡èƒŒæ™¯æ ·æœ¬
    if len(candidates) > 0:
        # èƒŒæ™¯é‡‡æ ·ï¼ˆå‡å°‘èƒŒæ™¯æ ·æœ¬æ•°é‡ï¼Œé‡ç‚¹æµ‹è¯•ç‰©ä½“ï¼‰
        bg_count = 0
        bg_stride = BACKGROUND_STRIDE * 2  # æ›´ç¨€ç–çš„èƒŒæ™¯é‡‡æ ·
        max_bg_samples = 5  # æœ€å¤š5ä¸ªèƒŒæ™¯æ ·æœ¬
        for v in range(0, height, bg_stride):
            for u in range(0, width, bg_stride):
                if not object_mask[v, u] and depth[v, u] > MIN_DEPTH:
                    candidates.append((u, v, 0, 0.0))
                    bg_count += 1
                    if bg_count >= max_bg_samples:
                        break
            if bg_count >= max_bg_samples:
                break
        
        fg_count = len(candidates) - bg_count
        print(f"   ğŸ“ é‡‡æ · {len(candidates)} ä¸ªå€™é€‰ (å‰æ™¯: {fg_count}, èƒŒæ™¯: {bg_count})")
    else:
        print(f"   âš ï¸  æ— æ³•ç”Ÿæˆå€™é€‰ç‚¹ï¼Œç‰©ä½“åŒºåŸŸä¸ºç©º")
    
    if visualize and len(candidates) > 100:
        # åœ¨å¯è§†åŒ–æ¨¡å¼ä¸‹ï¼Œä¼˜å…ˆæµ‹è¯•å‰æ™¯å€™é€‰
        print(f"   ğŸ§ª å¯è§†åŒ–æ¨¡å¼ï¼šæµ‹è¯•å‰ 100 ä¸ªï¼ˆä¼˜å…ˆå‰æ™¯ï¼‰")
        candidates = candidates[:100]
    
    return candidates


def fast_grasp_test(robot_id, world_pos, grasp_angle, object_ids, visualize=False):
    """å¿«é€ŸæŠ“å–æµ‹è¯•"""
    ee_link = 11
    steps = SLOW_STEPS if visualize else FAST_STEPS
    
    # æ£€æŸ¥Zåæ ‡
    if world_pos[2] < TABLE_TOP_Z - 0.05 or world_pos[2] > TABLE_TOP_Z + 0.30:
        if visualize:
            print(f"         âš ï¸  Zåæ ‡ä¸åˆç† ({world_pos[2]:.3f}m)")
        return False
    
    # æ£€æŸ¥XYå·¥ä½œç©ºé—´
    dist = np.sqrt(world_pos[0]**2 + world_pos[1]**2)
    if dist < 0.35 or dist > 0.80:
        if visualize:
            print(f"         âš ï¸  è¶…å‡ºå·¥ä½œèŒƒå›´ (è·ç¦»={dist:.3f}m)")
        return False
    
    initial_z = {}
    initial_pos = {}
    for obj_id in object_ids:
        pos, _ = p.getBasePositionAndOrientation(obj_id)
        initial_z[obj_id] = pos[2]
        initial_pos[obj_id] = pos
    
    try:
        ori = p.getQuaternionFromEuler([np.pi, 0, grasp_angle])
        
        # é¢„æŠ“å–
        if visualize:
            print(f"         â†‘ é¢„æŠ“å–...")
        pre_pos = [world_pos[0], world_pos[1], world_pos[2] + PRE_GRASP_OFFSET]
        if not move_fast(robot_id, ee_link, pre_pos, ori, steps):
            return False
        
        # æ£€æŸ¥ç‰©ä½“æ˜¯å¦è¢«æ¨èµ°ï¼ˆé¢„æŠ“å–é˜¶æ®µä¸åº”è¯¥ç¢°åˆ°ç‰©ä½“ï¼‰
        for obj_id in object_ids:
            pos, _ = p.getBasePositionAndOrientation(obj_id)
            xy_dist = np.sqrt((pos[0]-initial_pos[obj_id][0])**2 + (pos[1]-initial_pos[obj_id][1])**2)
            if xy_dist > 0.05:  # ç§»åŠ¨è¶…è¿‡5cm
                if visualize:
                    print(f"         âš ï¸  é¢„æŠ“å–æ—¶ç‰©ä½“ID={obj_id}è¢«æ¨èµ° {xy_dist*100:.1f}cm")
                return False
        
        # ä¸‹é™
        if visualize:
            print(f"         â†“ ä¸‹é™...")
        grasp_pos = [world_pos[0], world_pos[1], world_pos[2] + GRASP_OFFSET]
        if visualize:
            print(f"            ç›®æ ‡æ·±åº¦: Z={grasp_pos[2]:.3f}m (ç‰©ä½“={world_pos[2]:.3f}m, offset={GRASP_OFFSET:+.3f}m)")
        if not move_fast(robot_id, ee_link, grasp_pos, ori, steps, slow=True):
            return False
        
        # æ£€æŸ¥ç‰©ä½“æ˜¯å¦è¢«æ¨èµ°ï¼ˆä¸‹é™é˜¶æ®µè½»å¾®ç¢°è§¦æ˜¯å¯ä»¥çš„ï¼‰
        for obj_id in object_ids:
            pos, _ = p.getBasePositionAndOrientation(obj_id)
            xy_dist = np.sqrt((pos[0]-initial_pos[obj_id][0])**2 + (pos[1]-initial_pos[obj_id][1])**2)
            if xy_dist > 0.05:
                if visualize:
                    print(f"         âš ï¸  ä¸‹é™æ—¶ç‰©ä½“ID={obj_id}è¢«æ¨èµ° {xy_dist*100:.1f}cm")
                return False
        
        # æ£€æŸ¥å®é™…åˆ°è¾¾çš„ä½ç½®
        if visualize:
            actual_pos = p.getLinkState(robot_id, ee_link)[0]
            print(f"            å®é™…ä½ç½®: [{actual_pos[0]:.3f}, {actual_pos[1]:.3f}, {actual_pos[2]:.3f}]")
        
        # é—­åˆå¤¹çˆª
        if visualize:
            print(f"         ğŸ¤ é—­åˆ...")
        close_gripper_slow(robot_id, steps//2)
        
        # æ£€æŸ¥å¤¹çˆª
        finger_state = p.getJointState(robot_id, 9)[0]
        if visualize:
            print(f"            å¤¹çˆªçŠ¶æ€: {finger_state:.4f} (0=å®Œå…¨æ‰“å¼€, åº”è¯¥>0.001)")
        if finger_state < 0.001:
            if visualize:
                print(f"         âš ï¸  å¤¹çˆªæœªé—­åˆï¼ˆç‰©ä½“å¤ªå°æˆ–ä½ç½®ä¸å¯¹ï¼‰")
            return False
        
        # æŠ¬èµ·
        if visualize:
            print(f"         â†‘â†‘ æŠ¬èµ·...")
        lift_pos = [grasp_pos[0], grasp_pos[1], world_pos[2] + LIFT_HEIGHT]
        if not move_fast(robot_id, ee_link, lift_pos, ori, steps):
            return False
        
        # åˆ¤æ–­æˆåŠŸ
        for obj_id in object_ids:
            pos, _ = p.getBasePositionAndOrientation(obj_id)
            if pos[2] - initial_z[obj_id] > 0.08:
                if visualize:
                    print(f"         âœ… æˆåŠŸï¼æŠ¬èµ· {(pos[2]-initial_z[obj_id])*100:.1f}cm")
                return True
        
        if visualize:
            print(f"         âŒ å¤±è´¥")
        return False
    
    except Exception as e:
        if visualize:
            print(f"         âš ï¸ å¼‚å¸¸: {e}")
        return False


def move_fast(robot_id, ee_link, target_pos, target_ori, max_steps, slow=False):
    """ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®"""
    ll, ul, jr, rp = [], [], [], []
    for i in range(7):
        info = p.getJointInfo(robot_id, i)
        ll.append(info[8])
        ul.append(info[9])
        jr.append(info[9] - info[8])
        rp.append(p.getJointState(robot_id, i)[0])
    
    joints = p.calculateInverseKinematics(
        robot_id, ee_link, target_pos, target_ori,
        lowerLimits=ll, upperLimits=ul, jointRanges=jr, restPoses=rp
    )
    
    if not joints or len(joints) < 7:
        return False
    
    velocity = 0.3 if slow else 1.0
    force = 300 if slow else 500
    
    for i in range(7):
        p.setJointMotorControl2(
            robot_id, i, p.POSITION_CONTROL,
            targetPosition=joints[i], force=force, maxVelocity=velocity
        )
    
    for _ in range(max_steps):
        p.stepSimulation()
        time.sleep(1./240.)
    
    current = p.getLinkState(robot_id, ee_link)[0]
    dist = np.linalg.norm(np.array(current) - np.array(target_pos))
    return dist < 0.10


def close_gripper_slow(robot_id, steps):
    """æ…¢é€Ÿé—­åˆå¤¹çˆª"""
    pos = GRIPPER_CLOSED / 2.0
    p.setJointMotorControl2(robot_id, 9, p.POSITION_CONTROL, targetPosition=pos, force=50, maxVelocity=0.05)
    p.setJointMotorControl2(robot_id, 10, p.POSITION_CONTROL, targetPosition=pos, force=50, maxVelocity=0.05)
    for _ in range(steps):
        p.stepSimulation()
        time.sleep(1./240.)


def open_gripper_fast(robot_id):
    """æ‰“å¼€å¤¹çˆª"""
    pos = 0.04 / 2.0
    p.setJointMotorControl2(robot_id, 9, p.POSITION_CONTROL, targetPosition=pos, force=50)
    p.setJointMotorControl2(robot_id, 10, p.POSITION_CONTROL, targetPosition=pos, force=50)
    for _ in range(10):
        p.stepSimulation()


def reset_robot_home(robot_id):
    """é‡ç½®æœºå™¨äººåˆ°åˆå§‹ä½ç½®"""
    home = [0, -0.785, 0, -2.356, 0, 1.571, 0.785]
    
    # ä½¿ç”¨ä½ç½®æ§åˆ¶è€Œä¸æ˜¯ç›´æ¥è®¾ç½®å…³èŠ‚çŠ¶æ€ï¼Œæ›´å¹³æ»‘
    for i in range(7):
        p.setJointMotorControl2(
            robot_id, i, p.POSITION_CONTROL,
            targetPosition=home[i], 
            force=500, 
            maxVelocity=2.0
        )
    
    # ç¡®ä¿å¤¹çˆªæ‰“å¼€
    open_gripper_fast(robot_id)
    
    # ç­‰å¾…åˆ°ä½
    for _ in range(120):
        p.stepSimulation()
        
        # æ£€æŸ¥æ˜¯å¦åˆ°ä½
        all_in_position = True
        for i in range(7):
            current = p.getJointState(robot_id, i)[0]
            if abs(current - home[i]) > 0.05:  # å®¹å·®3åº¦
                all_in_position = False
                break
        
        if all_in_position:
            break


def generate_scene_data(scene_id, num_objects=3, visualize=False):
    """ç”Ÿæˆå•ä¸ªåœºæ™¯æ•°æ®"""
    print(f"\nğŸ¬ åœºæ™¯ {scene_id:04d}")
    
    client = p.connect(p.GUI if visualize else p.DIRECT)
    if client < 0:
        return False
    
    try:
        robot_id, object_ids = setup_environment(num_objects=num_objects)
        if not object_ids:
            return False
        
        print("   â³ ç­‰å¾…ç‰©ä½“ç¨³å®š...")
        for _ in range(120):
            p.stepSimulation()
        
        # ç¡®ä¿æœºå™¨äººåœ¨åˆå§‹ä½ç½®
        reset_robot_home(robot_id)
        for _ in range(60):
            p.stepSimulation()
        
        if visualize:
            print("   â¸ï¸  æŒ‰ Enter ç»§ç»­...")
            input()
        
        # ä¸»å¾ªç¯ï¼šæŒç»­æŠ“å–ç›´åˆ°æ²¡æœ‰ç‰©ä½“
        total_samples = 0
        total_success = 0
        grasp_attempt = 0
        consecutive_failures = 0  # è¿ç»­å¤±è´¥è®¡æ•°å™¨
        
        # ç”¨äºä¿å­˜æœ€ç»ˆæ•°æ®çš„å˜é‡
        final_rgb = None
        final_depth = None
        final_label = None
        
        while grasp_attempt < 50:  # æœ€å¤š50æ¬¡æŠ“å–å°è¯•
            grasp_attempt += 1
            
            # âœ¨ å…³é”®ä¿®å¤ï¼šæ¯æ¬¡æŠ“å–å°è¯•å‰éƒ½æ›´æ–°ç›¸æœºï¼
            print(f"\n   ğŸ“¸ æ›´æ–°ç›¸æœºå›¾åƒ (å°è¯• {grasp_attempt}, å‰©ä½™ç‰©ä½“: {len(object_ids)})")
            
            # ç¡®ä¿æœºå™¨äººåœ¨å®¶ä½ç½®
            print("   ğŸ  ç¡®ä¿æœºå™¨äººå›åˆ°åˆå§‹ä½ç½®...")
            reset_robot_home(robot_id)
            
            # ç­‰å¾…æœºå™¨äººå®Œå…¨ç¨³å®š
            for _ in range(120):
                p.stepSimulation()
            
            # éªŒè¯æœºå™¨äººä½ç½®
            if visualize:
                home_joints = [0, -0.785, 0, -2.356, 0, 1.571, 0.785]
                current_joints = []
                for i in range(7):
                    current_joints.append(p.getJointState(robot_id, i)[0])
                
                joint_errors = [abs(current_joints[i] - home_joints[i]) for i in range(7)]
                max_error = max(joint_errors)
                print(f"   ğŸ¯ å…³èŠ‚è¯¯å·®: æœ€å¤§ {max_error:.4f} rad")
                
                if max_error > 0.1:
                    print(f"   âš ï¸  æœºå™¨äººæœªå®Œå…¨å½’ä½ï¼Œé‡è¯•...")
                    reset_robot_home(robot_id)
                    for _ in range(180):
                        p.stepSimulation()
            
            # æ‹æ‘„æ–°ç…§ç‰‡ - åæ˜ å½“å‰åœºæ™¯çŠ¶æ€
            width, height, view_matrix, proj_matrix = set_topdown_camera()
            rgb, depth, seg_mask = get_rgb_depth_segmentation(width, height, view_matrix, proj_matrix)
            
            # ä¿å­˜å½“å‰å›¾åƒ
            final_rgb = rgb.copy()
            final_depth = depth.copy()
            
            # æ›´æ–°æ´»è·ƒç‰©ä½“åˆ—è¡¨ - å…³é”®ä¿®å¤ï¼
            from environment_setup import update_object_states
            object_ids = update_object_states(object_ids)
            
            # âœ¨ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç‰©ä½“
            if len(object_ids) == 0:
                print("   âœ… æ‰€æœ‰ç‰©ä½“å·²è¢«ç§»é™¤ï¼Œåœºæ™¯å®Œæˆï¼")
                break
            
            if visualize:
                for i, obj_id in enumerate(object_ids):
                    try:
                        pos, _ = p.getBasePositionAndOrientation(obj_id)
                        print(f"   ğŸ“¦ ç‰©ä½“{i+1} (ID={obj_id}): [{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}]")
                    except:
                        print(f"   âŒ ç‰©ä½“{i+1} (ID={obj_id}): å·²ä¸å­˜åœ¨")
            
                        # åŸºäºå½“å‰å›¾åƒé‡‡æ ·å€™é€‰
            candidates = sample_grasp_candidates(depth, NUM_ANGLES, visualize, rgb, view_matrix, proj_matrix, seg_mask, object_ids)
            
            if len(candidates) == 0:
                print("   âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆå€™é€‰ç‚¹")
                consecutive_failures += 1
                
                # âœ¨ ç«‹å³é‡æ–°ç”Ÿæˆç‰©ä½“ï¼Œä¸è¦ç­‰å¾…5æ¬¡å¤±è´¥
                print("   ğŸ”„ æ¡Œé¢ä¸ºç©ºæˆ–æ— æœ‰æ•ˆå€™é€‰ï¼Œé‡æ–°ç”Ÿæˆç‰©ä½“...")
                from environment_setup import reset_objects_after_grasp
                object_ids = reset_objects_after_grasp([], min_objects=3)  # ä¼ å…¥ç©ºåˆ—è¡¨å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
                consecutive_failures = 0
                
                # å¦‚æœé‡æ–°ç”Ÿæˆåä»ç„¶æ²¡æœ‰ç‰©ä½“ï¼Œç»“æŸè¿™ä¸ªåœºæ™¯
                if len(object_ids) == 0:
                    print("   âŒ æ— æ³•ç”Ÿæˆæ–°ç‰©ä½“ï¼Œç»“æŸåœºæ™¯")
                    break
                    
                # é‡æ–°ç”Ÿæˆåç»§ç»­ä¸‹ä¸€è½®å¾ªç¯
                continue
            
            # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨
            consecutive_failures = 0
            
            # æµ‹è¯•ç¬¬ä¸€ä¸ªæœ€æœ‰å¸Œæœ›çš„å€™é€‰ï¼ˆæ¯æ¬¡åªæµ‹è¯•ä¸€ä¸ªï¼‰
            u, v, theta_idx, theta = candidates[0]
            
            if depth[v, u] < MIN_DEPTH:
                print("   âš ï¸  å€™é€‰æ·±åº¦æ— æ•ˆ")
                continue
            
            total_samples += 1
            
            if visualize:
                print(f"\n      === æµ‹è¯•å€™é€‰ ===")
                print(f"         åƒç´ : ({u}, {v}), è§’åº¦: {np.degrees(theta):.1f}Â°")
            
            world_pos = pixel_to_world(u, v, depth[v, u], view_matrix, proj_matrix)
            
            if visualize:
                print(f"         ä¸–ç•Œåæ ‡: [{world_pos[0]:.3f}, {world_pos[1]:.3f}, {world_pos[2]:.3f}]")
            
            # æ‰§è¡ŒæŠ“å–æµ‹è¯•
            success = fast_grasp_test(robot_id, world_pos, theta, object_ids, visualize)
            
            if success:
                total_success += 1
                print(f"      âœ… æˆåŠŸæŠ“å–ï¼")
                
                # åˆ›å»º/æ›´æ–°æ ‡ç­¾
                if final_label is None:
                    final_label = np.zeros((height, width, NUM_ANGLES + 1), dtype=np.uint8)
                
                final_label[v, u, theta_idx] = 1
                
                # ç«‹å³æ›´æ–°ç‰©ä½“åˆ—è¡¨
                object_ids = update_object_states(object_ids)
                print(f"      ğŸ“¦ å‰©ä½™ç‰©ä½“: {len(object_ids)}")
                
                # âœ¨ å¦‚æœæ‰€æœ‰ç‰©ä½“éƒ½è¢«ç§»é™¤ï¼Œç»“æŸå¾ªç¯
                if len(object_ids) == 0:
                    print("   ğŸ‰ æ‰€æœ‰ç‰©ä½“å·²æˆåŠŸæŠ“å–ï¼")
                    break
                
            else:
                print(f"      âŒ æŠ“å–å¤±è´¥")
                consecutive_failures += 1
            
            if grasp_attempt % 10 == 0:
                print(f"   ğŸ“Š è¿›åº¦: {grasp_attempt} æ¬¡å°è¯•, æˆåŠŸ: {total_success}, æˆåŠŸç‡: {100*total_success/total_samples if total_samples > 0 else 0:.1f}%")
            
            # å¦‚æœè¿ç»­å¤šæ¬¡å¤±è´¥ï¼Œé‡æ–°ç”Ÿæˆç‰©ä½“
            if consecutive_failures >= 10:
                print("   ğŸ”„ è¿ç»­å¤±è´¥è¿‡å¤šï¼Œé‡æ–°ç”Ÿæˆç‰©ä½“...")
                from environment_setup import reset_objects_after_grasp
                object_ids = reset_objects_after_grasp(object_ids, min_objects=2)
                consecutive_failures = 0
                
                # å¦‚æœé‡æ–°ç”Ÿæˆåä»ç„¶æ²¡æœ‰ç‰©ä½“ï¼Œç»“æŸè¿™ä¸ªåœºæ™¯
                if len(object_ids) == 0:
                    print("   âŒ æ— æ³•ç”Ÿæˆæ–°ç‰©ä½“ï¼Œç»“æŸåœºæ™¯")
                    break
        
        # å®Œæˆæœ€ç»ˆæ ‡ç­¾
        if final_label is not None:
            # è®¾ç½®èƒŒæ™¯æ ‡ç­¾
            has_success = final_label[:, :, :-1].sum(axis=2) > 0
            final_label[:, :, -1] = (~has_success).astype(np.uint8)
            
            final_rate = total_success / total_samples if total_samples > 0 else 0
            print(f"\n   âœ… æ€»ä½“æˆåŠŸç‡: {final_rate*100:.1f}% ({total_success}/{total_samples})")
            
            # ä¿å­˜æœ€ç»ˆæ•°æ®
            save_scene_data(scene_id, final_rgb, final_depth, final_label, {
                "num_objects": num_objects,
                "num_samples": total_samples,
                "success_count": int(total_success),
                "success_rate": final_rate,
                "grasp_attempts": grasp_attempt
            })
        else:
            print(f"   âš ï¸  åœºæ™¯ {scene_id} æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•°æ®")
        
        return True
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        print(f"   ğŸ”š æ–­å¼€è¿æ¥...")
        p.disconnect()

def save_scene_data(scene_id, rgb, depth, label, metadata):
    """ä¿å­˜æ•°æ®"""
    prefix = DATA_DIR / f"scene_{scene_id:04d}"
    cv2.imwrite(str(prefix) + "_rgb.png", cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))
    np.save(str(prefix) + "_depth.npy", depth)
    np.save(str(prefix) + "_label.npy", label)
    with open(str(prefix) + "_meta.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"   ğŸ’¾ ä¿å­˜: {prefix}_*")


def generate_dataset(num_scenes, num_objects_range=(1, 3), visualize_first=False):
    """æ‰¹é‡ç”Ÿæˆ"""
    print("=" * 60)
    print("ğŸš€ ç”Ÿæˆæ•°æ®é›†")
    print("=" * 60)
    
    create_data_dirs()
    success_scenes = 0
    start = time.time()
    
    for scene_id in range(num_scenes):
        num_objects = np.random.randint(num_objects_range[0], num_objects_range[1] + 1)
        vis = visualize_first and (scene_id == 0)
        
        if generate_scene_data(scene_id, num_objects, vis):
            success_scenes += 1
    
    elapsed = time.time() - start
    print("\n" + "=" * 60)
    print(f"âœ… å®Œæˆï¼{success_scenes}/{num_scenes}")
    print(f"   è€—æ—¶: {elapsed:.1f}s ({elapsed/num_scenes:.1f}s/åœºæ™¯)")
    print(f"   ä½ç½®: {DATA_DIR.absolute()}")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--num_scenes", type=int, default=10)
    parser.add_argument("--num_objects", type=int, nargs=2, default=[1, 3])
    parser.add_argument("--visualize_first", action="store_true")
    args = parser.parse_args()
    
    generate_dataset(
        num_scenes=args.num_scenes,
        num_objects_range=tuple(args.num_objects),
        visualize_first=args.visualize_first
    )


if __name__ == "__main__":
    main()


def estimate_object_height(depth, object_mask, percentile=10):
    """ä¼°è®¡ç‰©ä½“è¡¨é¢é«˜åº¦
    
    ä½¿ç”¨æ£€æµ‹åˆ°çš„ç‰©ä½“åƒç´ çš„æ·±åº¦å€¼ä¼°è®¡è¡¨é¢é«˜åº¦
    ä½¿ç”¨è¾ƒå°ç™¾åˆ†ä½æ•°æ¥é¿å…å™ªå£°å’Œè¾¹ç¼˜æ•ˆåº”
    
    Args:
        depth: æ·±åº¦å›¾
        object_mask: ç‰©ä½“mask
        percentile: ä½¿ç”¨çš„ç™¾åˆ†ä½æ•°ï¼ˆé»˜è®¤10 = æœ€è¿‘çš„10%åƒç´ ï¼‰
    
    Returns:
        ç‰©ä½“è¡¨é¢é«˜åº¦ï¼ˆä¸–ç•Œåæ ‡Zå€¼ï¼‰
    """
    obj_depths = depth[object_mask]
    valid_depths = obj_depths[obj_depths > MIN_DEPTH]
    
    if len(valid_depths) == 0:
        return None
    
    # ä½¿ç”¨è¾ƒå°ç™¾åˆ†ä½æ•°çš„æ·±åº¦å€¼ï¼ˆæœ€æ¥è¿‘ç›¸æœº = æœ€é«˜ç‚¹ï¼‰
    surface_depth = np.percentile(valid_depths, percentile)
    
    # æ·±åº¦åˆ°ä¸–ç•ŒZçš„è½¬æ¢ï¼ˆç®€åŒ–ç‰ˆï¼Œå‡è®¾ä¿¯è§†ç›¸æœºï¼‰
    # ç›¸æœºé«˜åº¦ = TABLE_TOP_Z + camera_distance
    # ç‰©ä½“Z = ç›¸æœºé«˜åº¦ - æ·±åº¦
    camera_height = TABLE_TOP_Z + 1.2  # CAMERA_DISTANCE = 1.2
    object_z = camera_height - surface_depth
    
    return object_z
