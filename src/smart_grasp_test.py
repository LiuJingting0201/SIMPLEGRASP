#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æŠ“å–æµ‹è¯• - è‡ªåŠ¨æ‰¾åˆ°ç‰©ä½“ä½ç½®è¿›è¡ŒæŠ“å–
"""
import pybullet as p
import numpy as np
import cv2
import time
from geom import (setup_scene, set_topdown_camera, get_rgb_depth, 
                  pixel_to_world_on_plane, TABLE_TOP_Z)

def find_object_pixels(rgb, depth):
    """åœ¨å›¾åƒä¸­æ‰¾åˆ°ç‰©ä½“åƒç´ ç‚¹"""
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)
    
    # ç®€å•çš„ç‰©ä½“æ£€æµ‹ï¼šå¯»æ‰¾éæ¡Œé¢é¢œè‰²çš„åŒºåŸŸ
    # æ¡Œé¢é€šå¸¸æ˜¯æ£•è‰²/ç°è‰²ï¼Œç‰©ä½“æ˜¯ç™½è‰²
    
    # é˜ˆå€¼åŒ–æ‰¾åˆ°æ˜äº®åŒºåŸŸï¼ˆå‡è®¾ç‰©ä½“æ˜¯ç™½è‰²çš„ï¼‰
    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    
    # æ‰¾åˆ°è½®å»“
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    object_points = []
    for contour in contours:
        # è¿‡æ»¤å¤ªå°çš„è½®å»“
        if cv2.contourArea(contour) > 100:  # æœ€å°é¢ç§¯é˜ˆå€¼
            # è·å–è½®å»“ä¸­å¿ƒ
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                object_points.append((cx, cy))
    
    return object_points

def smart_grasp_test():
    """æ™ºèƒ½æŠ“å–æµ‹è¯• - è‡ªåŠ¨æ‰¾ç‰©ä½“"""
    print("ğŸ§  å¼€å§‹æ™ºèƒ½æŠ“å–æµ‹è¯•...")
    
    # è¿æ¥ä»¿çœŸ
    p.connect(p.GUI)
    
    try:
        # è®¾ç½®åœºæ™¯
        robot_id, table_id, obj_ids = setup_scene(add_objects=True, n_objects=2)
        print(f"âœ… åœºæ™¯è®¾ç½®å®Œæˆï¼Œç‰©ä½“æ•°é‡: {len(obj_ids)}")
        
        # è·å–ç›¸æœºå›¾åƒ
        W, H, view, proj = set_topdown_camera()
        rgb, depth = get_rgb_depth(W, H, view, proj)
        print(f"ğŸ“· ç›¸æœºå›¾åƒè·å–å®Œæˆ: {rgb.shape}")
        
        # ä¿å­˜åŸå§‹å›¾åƒç”¨äºè°ƒè¯•
        cv2.imwrite("../data/debug_rgb.png", cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))
        print("ğŸ–¼ï¸ è°ƒè¯•å›¾åƒå·²ä¿å­˜åˆ° ../data/debug_rgb.png")
        
        # è®°å½•ç‰©ä½“çœŸå®ä½ç½®
        print("\nğŸ“ ç‰©ä½“çœŸå®ä½ç½®:")
        for i, obj_id in enumerate(obj_ids):
            pos, _ = p.getBasePositionAndOrientation(obj_id)
            print(f"   ç‰©ä½“{i+1}: {pos}")
        
        # æ™ºèƒ½æ£€æµ‹ç‰©ä½“åƒç´ 
        object_pixels = find_object_pixels(rgb, depth)
        print(f"\nğŸ” æ£€æµ‹åˆ° {len(object_pixels)} ä¸ªç‰©ä½“åƒç´ ç‚¹:")
        
        if not object_pixels:
            print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°ç‰©ä½“ï¼Œå°è¯•æ‰‹åŠ¨é€‰æ‹©...")
            # å›é€€åˆ°å›¾åƒä¸­å¿ƒ
            object_pixels = [(W//2, H//2)]
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“
        target_u, target_v = object_pixels[0]
        print(f"ğŸ¯ é€‰æ‹©ç›®æ ‡: åƒç´ ({target_u}, {target_v})")
        
        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡
        world_pos = pixel_to_world_on_plane(target_u, target_v, W, H, view, proj)
        print(f"   ä¸–ç•Œåæ ‡: {world_pos}")
        
        if world_pos is not None:
            # æ‰§è¡ŒæŠ“å–
            print(f"\nğŸ¦¾ å¼€å§‹æŠ“å–...")
            success = attempt_grasp_with_feedback(robot_id, world_pos, 0.0)
            print(f"\nğŸ“Š æŠ“å–ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        
        print(f"\nğŸ® æµ‹è¯•å®Œæˆï¼")
        print("æŒ‰ Enter é”®é€€å‡º...")
        input()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        p.disconnect()

def attempt_grasp_with_feedback(robot_id, world_pos, grasp_angle):
    """å¸¦åé¦ˆçš„æŠ“å–å‡½æ•°"""
    print(f"   ğŸ“ ç›®æ ‡ä½ç½®: {world_pos}")
    print(f"   ğŸ”„ æŠ“å–è§’åº¦: {np.degrees(grasp_angle):.1f}Â°")
    
    # æ£€æŸ¥ç›®æ ‡ä½ç½®æ˜¯å¦åˆç†
    if world_pos[2] < TABLE_TOP_Z - 0.1 or world_pos[2] > TABLE_TOP_Z + 0.1:
        print(f"   âš ï¸  ç›®æ ‡é«˜åº¦å¼‚å¸¸: {world_pos[2]:.3f} (æ¡Œé¢: {TABLE_TOP_Z})")
    
    # æŠ“å–å‚æ•°
    pre_grasp_height = TABLE_TOP_Z + 0.15
    grasp_height = TABLE_TOP_Z + 0.02  # æ›´æ¥è¿‘æ¡Œé¢
    lift_height = TABLE_TOP_Z + 0.25
    
    euler = [0, np.pi, grasp_angle]
    grasp_ori = p.getQuaternionFromEuler(euler)
    ee_link = 11
    
    try:
        # è®°å½•å‘¨å›´ç‰©ä½“çš„åˆå§‹ä½ç½®
        nearby_objects = []
        for body_id in range(p.getNumBodies()):
            if body_id != 0 and body_id != robot_id:  # æ’é™¤åœ°é¢å’Œæœºå™¨äºº
                try:
                    pos, _ = p.getBasePositionAndOrientation(body_id)
                    dist = np.linalg.norm(np.array(pos[:2]) - np.array(world_pos[:2]))
                    if dist < 0.1:  # 10cmèŒƒå›´å†…
                        nearby_objects.append((body_id, pos))
                        print(f"   ğŸ¯ é™„è¿‘ç‰©ä½“: ID{body_id}, è·ç¦»{dist:.3f}m")
                except:
                    pass
        
        # æ‰§è¡ŒæŠ“å–åŠ¨ä½œï¼ˆç®€åŒ–ç‰ˆï¼‰
        print("   â¬†ï¸  ç§»åŠ¨åˆ°é¢„æŠ“å–ä½ç½®...")
        
        # 1. é¢„æŠ“å–
        pre_grasp_pos = world_pos.copy()
        pre_grasp_pos[2] = pre_grasp_height
        joints_pre = p.calculateInverseKinematics(robot_id, ee_link, pre_grasp_pos, grasp_ori)
        
        for i in range(7):
            p.setJointMotorControl2(robot_id, i, p.POSITION_CONTROL, joints_pre[i])
        
        p.setJointMotorControl2(robot_id, 9, p.POSITION_CONTROL, 0.04)
        p.setJointMotorControl2(robot_id, 10, p.POSITION_CONTROL, 0.04)
        
        for _ in range(100):
            p.stepSimulation()
            time.sleep(1./240.)
        
        print("   â¬‡ï¸  ä¸‹é™å¹¶æŠ“å–...")
        
        # 2. ä¸‹é™å’ŒæŠ“å–
        grasp_pos = world_pos.copy()
        grasp_pos[2] = grasp_height
        joints_grasp = p.calculateInverseKinematics(robot_id, ee_link, grasp_pos, grasp_ori)
        
        for i in range(7):
            p.setJointMotorControl2(robot_id, i, p.POSITION_CONTROL, joints_grasp[i])
        
        for _ in range(80):
            p.stepSimulation()
            time.sleep(1./240.)
        
        # 3. é—­åˆå¤¹çˆª
        p.setJointMotorControl2(robot_id, 9, p.POSITION_CONTROL, 0.0)
        p.setJointMotorControl2(robot_id, 10, p.POSITION_CONTROL, 0.0)
        
        for _ in range(60):
            p.stepSimulation()
            time.sleep(1./240.)
        
        print("   â¬†ï¸  æŠ¬èµ·...")
        
        # 4. æŠ¬èµ·
        lift_pos = world_pos.copy()
        lift_pos[2] = lift_height
        joints_lift = p.calculateInverseKinematics(robot_id, ee_link, lift_pos, grasp_ori)
        
        for i in range(7):
            p.setJointMotorControl2(robot_id, i, p.POSITION_CONTROL, joints_lift[i])
        
        for _ in range(100):
            p.stepSimulation()
            time.sleep(1./240.)
        
        # 5. æ£€æŸ¥ç»“æœ
        success = False
        for body_id, initial_pos in nearby_objects:
            try:
                final_pos, _ = p.getBasePositionAndOrientation(body_id)
                height_change = final_pos[2] - initial_pos[2]
                
                if final_pos[2] > TABLE_TOP_Z + 0.08:
                    success = True
                    print(f"   âœ… ç‰©ä½“ID{body_id}è¢«æŠ¬èµ· {height_change:+.3f}m åˆ° {final_pos[2]:.3f}m")
                    break
                else:
                    print(f"   ğŸ“ ç‰©ä½“ID{body_id}é«˜åº¦å˜åŒ– {height_change:+.3f}m")
            except:
                print(f"   â“ ç‰©ä½“ID{body_id}çŠ¶æ€æœªçŸ¥")
        
        return success
        
    except Exception as e:
        print(f"   âŒ æŠ“å–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    smart_grasp_test()
