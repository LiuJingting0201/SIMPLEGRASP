#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–å¯ä¾›æ€§è®­ç»ƒæ•°æ®æ”¶é›†å™¨
Automatic Affordance Training Data Collector

åŸºäºå·²éªŒè¯çš„å·¥ä½œç³»ç»Ÿï¼Œè‡ªåŠ¨æ”¶é›†è®­ç»ƒæ•°æ®
"""

import numpy as np
import cv2
import os
import json
import time
import argparse
import pybullet as p
from pathlib import Path
import sys

# å¯¼å…¥å·¥ä½œçš„æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
from src.environment_setup import setup_environment
from src.perception import set_topdown_camera, get_rgb_depth_segmentation, pixel_to_world
from src.afford_data_gen import sample_grasp_candidates, fast_grasp_test, reset_robot_home

class AutoAffordanceCollector:
    """è‡ªåŠ¨åŒ–å¯ä¾›æ€§æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, data_dir="data/affordance_v5", num_angles=8):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.num_angles = num_angles
        
        # æŠ“å–è§’åº¦è®¾ç½®
        self.grasp_angles = np.linspace(0, 2*np.pi, num_angles, endpoint=False)
        
        print(f"ğŸ¯ è‡ªåŠ¨åŒ–å¯ä¾›æ€§æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–")
        print(f"   æ•°æ®ç›®å½•: {self.data_dir.absolute()}")
        print(f"   æŠ“å–è§’åº¦æ•°: {num_angles}")
    
    def collect_single_scene(self, scene_id, num_objects=3, max_attempts=30):
        """æ”¶é›†å•ä¸ªåœºæ™¯çš„æ•°æ® - æ¯ä¸ªæŠ“å–å°è¯•å°±æ˜¯ä¸€ä¸ªå®Œæ•´åœºæ™¯"""
        print(f"\nğŸ¬ æ”¶é›†åœºæ™¯ {scene_id:04d} (ç‰©ä½“æ•°: {num_objects})")
        
        try:
            # 1. è®¾ç½®å…¨æ–°ç¯å¢ƒ
            robot_id, object_ids = setup_environment(num_objects=num_objects)
            if not object_ids:
                print("   âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥")
                return False
            
            # 2. é‡ç½®æœºå™¨äºº
            print("   ğŸ  é‡ç½®æœºå™¨äºº...")
            reset_robot_home(robot_id)
            
            # ç­‰å¾…ç¨³å®š
            for _ in range(60):
                p.stepSimulation()
                time.sleep(1./240.)
            
            # 3. æ‹æ‘„ç›¸æœºæ•°æ®
            width, height, view_matrix, proj_matrix = set_topdown_camera()
            rgb_image, depth_image, seg_mask = get_rgb_depth_segmentation(width, height, view_matrix, proj_matrix)
            
            print(f"   ğŸ“· ç›¸æœºæ•°æ®: RGB {rgb_image.shape}, æ·±åº¦ {depth_image.shape}")
            
            # 4. é‡‡æ ·å€™é€‰ç‚¹
            candidates = sample_grasp_candidates(
                depth=depth_image,
                num_angles=self.num_angles,
                visualize=False,
                rgb=rgb_image,
                view_matrix=view_matrix,
                proj_matrix=proj_matrix,
                seg_mask=seg_mask,
                object_ids=object_ids
            )
            
            if not candidates:
                print("   âŒ æ²¡æœ‰å€™é€‰ç‚¹")
                return False
            
            print(f"   ğŸ¯ æµ‹è¯• {min(3, len(candidates))} ä¸ªå€™é€‰ç‚¹...")
            
            # 5. åªæµ‹è¯•å°‘é‡å€™é€‰ç‚¹ (1-3ä¸ª) - æ¯ä¸ªåœºæ™¯å¿«é€Ÿå®Œæˆ
            results = []
            success_count = 0
            test_count = min(3, len(candidates))  # æœ€å¤šæµ‹è¯•3ä¸ª
            
            for i, candidate in enumerate(candidates[:test_count]):
                if len(candidate) == 4:
                    u, v, theta_idx, theta = candidate
                else:
                    u, v, theta_idx = candidate
                    theta = self.grasp_angles[theta_idx]
                
                world_pos = pixel_to_world(u, v, depth_image[v, u], view_matrix, proj_matrix)
                
                print(f"      ğŸ¯ æµ‹è¯• {i+1}/{test_count}: åƒç´ ({u},{v}), è§’åº¦{np.degrees(theta):.1f}Â°")
                
                # æµ‹è¯•æŠ“å–
                try:
                    success = fast_grasp_test(
                        robot_id=robot_id,
                        world_pos=world_pos,
                        grasp_angle=theta,
                        object_ids=object_ids,
                        visualize=False,
                        debug_mode=False
                    )
                    
                    if success:
                        success_count += 1
                        print(f"      âœ… æˆåŠŸ!")
                        
                        # è®°å½•ç»“æœå¹¶ç«‹å³ç»“æŸåœºæ™¯ (æ‰¾åˆ°æˆåŠŸå°±å¤Ÿäº†)
                        results.append({
                            'pixel': [int(u), int(v)],
                            'world_pos': [float(world_pos[0]), float(world_pos[1]), float(world_pos[2])],
                            'angle': float(theta),
                            'angle_idx': int(theta_idx),
                            'success': True
                        })
                        break  # æˆåŠŸå°±ç»“æŸè¿™ä¸ªåœºæ™¯
                    else:
                        print(f"      âŒ å¤±è´¥")
                        results.append({
                            'pixel': [int(u), int(v)],
                            'world_pos': [float(world_pos[0]), float(world_pos[1]), float(world_pos[2])],
                            'angle': float(theta),
                            'angle_idx': int(theta_idx),
                            'success': False
                        })
                    
                except Exception as e:
                    print(f"      âŒ é”™è¯¯: {e}")
                    results.append({
                        'pixel': [int(u), int(v)],
                        'world_pos': [0, 0, 0],
                        'angle': float(theta),
                        'angle_idx': int(theta_idx),
                        'success': False
                    })
            
            success_rate = (success_count / test_count) * 100 if test_count > 0 else 0
            print(f"   ğŸ“Š æˆåŠŸç‡: {success_count}/{test_count} ({success_rate:.1f}%)")
            
            # 6. ç”Ÿæˆå¯ä¾›æ€§åœ°å›¾
            affordance_map = self.generate_affordance_map(results, rgb_image.shape[:2])
            angle_map = self.generate_angle_map(results, rgb_image.shape[:2])
            
            # 7. ä¿å­˜æ•°æ®
            self.save_scene_data(scene_id, rgb_image, depth_image, affordance_map, angle_map, results)
            
            print(f"   âœ… åœºæ™¯ {scene_id} å®Œæˆ (æˆåŠŸç‡: {success_rate:.1f}%)")
            return True
            
        except Exception as e:
            print(f"   âŒ åœºæ™¯ {scene_id} å¤±è´¥: {e}")
            return False
    
    def is_position_reachable(self, world_pos):
        """æ£€æŸ¥ä½ç½®æ˜¯å¦åœ¨æœºå™¨äººå·¥ä½œç©ºé—´å†…"""
        x, y, z = world_pos
        
        # åŸºæœ¬å·¥ä½œç©ºé—´é™åˆ¶
        distance = np.sqrt(x**2 + y**2)
        
        # Franka Pandaçš„å·¥ä½œç©ºé—´çº¦æŸ
        if distance < 0.3 or distance > 0.85:  # è·ç¦»é™åˆ¶
            return False
        if abs(y) > 0.4:  # Yè½´é™åˆ¶
            return False
        if z < 0.58 or z > 0.8:  # Zè½´é«˜åº¦é™åˆ¶
            return False
        if x < 0.2 or x > 0.9:  # Xè½´å‰åé™åˆ¶
            return False
            
        return True
    
    def is_position_reachable(self, world_pos):
        """æ£€æŸ¥ä½ç½®æ˜¯å¦åœ¨æœºå™¨äººå·¥ä½œç©ºé—´å†…"""
        x, y, z = world_pos
        
        # åŸºæœ¬å·¥ä½œç©ºé—´é™åˆ¶
        distance = np.sqrt(x**2 + y**2)
        
        # Franka Pandaçš„å·¥ä½œç©ºé—´çº¦æŸ
        if distance < 0.3 or distance > 0.85:  # è·ç¦»é™åˆ¶
            return False
        if abs(y) > 0.4:  # Yè½´é™åˆ¶
            return False
        if z < 0.58 or z > 0.8:  # Zè½´é«˜åº¦é™åˆ¶
            return False
        if x < 0.2 or x > 0.9:  # Xè½´å‰åé™åˆ¶
            return False
            
        return True
    
    def generate_affordance_map(self, results, image_shape):
        """ç”Ÿæˆå¯ä¾›æ€§çƒ­åŠ›å›¾"""
        affordance_map = np.zeros(image_shape, dtype=np.float32)
        
        for result in results:
            if result['world_pos'][0] != 0:  # æœ‰æ•ˆçš„ä¸–ç•Œåæ ‡
                u, v = result['pixel']
                if 0 <= v < image_shape[0] and 0 <= u < image_shape[1]:
                    # æˆåŠŸä¸º1.0ï¼Œå¤±è´¥ä¸º0.0
                    affordance_map[v, u] = 1.0 if result['success'] else 0.0
        
        # è½»å¾®é«˜æ–¯æ¨¡ç³Šæ¥å¹³æ»‘çƒ­åŠ›å›¾
        affordance_map = cv2.GaussianBlur(affordance_map, (5, 5), 1.0)
        return affordance_map
    
    def generate_angle_map(self, results, image_shape):
        """ç”Ÿæˆæœ€ä½³æŠ“å–è§’åº¦åœ°å›¾"""
        angle_map = np.zeros(image_shape, dtype=np.float32)
        
        for result in results:
            if result['success'] and result['world_pos'][0] != 0:
                u, v = result['pixel']
                if 0 <= v < image_shape[0] and 0 <= u < image_shape[1]:
                    # å½’ä¸€åŒ–è§’åº¦åˆ° [0, 1]
                    normalized_angle = result['angle'] / (2 * np.pi)
                    angle_map[v, u] = normalized_angle
        
        return angle_map
    
    def save_scene_data(self, scene_id, rgb_image, depth_image, affordance_map, angle_map, results):
        """ä¿å­˜åœºæ™¯æ•°æ®"""
        scene_prefix = f"scene_{scene_id:04d}"
        
        # ä¿å­˜å›¾åƒ
        rgb_path = self.data_dir / f"{scene_prefix}_rgb.png"
        cv2.imwrite(str(rgb_path), cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))
        
        # ä¿å­˜æ·±åº¦å›¾
        depth_path = self.data_dir / f"{scene_prefix}_depth.npy"
        np.save(depth_path, depth_image)
        
        # ä¿å­˜å¯ä¾›æ€§åœ°å›¾
        affordance_path = self.data_dir / f"{scene_prefix}_affordance.npy"
        np.save(affordance_path, affordance_map)
        
        # ä¿å­˜è§’åº¦åœ°å›¾
        angle_path = self.data_dir / f"{scene_prefix}_angles.npy"
        np.save(angle_path, angle_map)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'scene_id': scene_id,
            'image_shape': rgb_image.shape[:2],
            'num_candidates': len(results),
            'num_successful': sum(1 for r in results if r['success']),
            'success_rate': sum(1 for r in results if r['success']) / len(results) if results else 0,
            'candidates': results
        }
        
        meta_path = self.data_dir / f"{scene_prefix}_meta.json"
        with open(meta_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"      ğŸ’¾ æ•°æ®å·²ä¿å­˜: {scene_prefix}_*")
    
    def collect_dataset(self, num_scenes, num_objects_range=(2, 4), max_attempts_per_scene=25):
        """æ”¶é›†å®Œæ•´æ•°æ®é›†"""
        print(f"\nğŸš€ å¼€å§‹æ”¶é›†æ•°æ®é›†")
        print(f"   åœºæ™¯æ•°é‡: {num_scenes}")
        print(f"   ç‰©ä½“æ•°é‡èŒƒå›´: {num_objects_range[0]}-{num_objects_range[1]}")
        print(f"   æ¯åœºæ™¯æœ€å¤§å°è¯•æ•°: {max_attempts_per_scene}")
        print("=" * 60)
        
        successful_scenes = 0
        total_success_rate = 0
        avg_success_rate = 0  # Initialize to avoid UnboundLocalError
        
        for scene_id in range(num_scenes):
            # éšæœºé€‰æ‹©ç‰©ä½“æ•°é‡
            num_objects = np.random.randint(num_objects_range[0], num_objects_range[1] + 1)
            
            # æ”¶é›†åœºæ™¯
            success = self.collect_single_scene(scene_id, num_objects, max_attempts_per_scene)
            
            # åœºæ™¯é—´çŸ­æš‚åœé¡¿ï¼Œè®©ç‰©ç†å¼•æ“ç¨³å®š
            if scene_id < num_scenes - 1:
                for _ in range(10):
                    p.stepSimulation()
                    time.sleep(1./240.)
            
            if success:
                successful_scenes += 1
                # è¯»å–æˆåŠŸç‡
                try:
                    meta_path = self.data_dir / f"scene_{scene_id:04d}_meta.json"
                    with open(meta_path, 'r') as f:
                        metadata = json.load(f)
                    total_success_rate += metadata['success_rate']
                except:
                    pass
            else:
                print(f"   âš ï¸  åœºæ™¯ {scene_id} æ”¶é›†å¤±è´¥ï¼Œè·³è¿‡")
        
        # æ€»ç»“
        avg_success_rate = (total_success_rate / successful_scenes) if successful_scenes > 0 else 0
        print("=" * 60)
        print(f"ğŸ‰ æ•°æ®æ”¶é›†å®Œæˆ!")
        print(f"   æˆåŠŸåœºæ™¯: {successful_scenes}/{num_scenes}")
        print(f"   å¹³å‡æˆåŠŸç‡: {avg_success_rate:.1f}%")
        print(f"   æ•°æ®ä¿å­˜åœ¨: {self.data_dir.absolute()}")
        print("âœ… æ•°æ®æ”¶é›†æˆåŠŸ!")
        
        return successful_scenes > 0

def main():
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ–å¯ä¾›æ€§è®­ç»ƒæ•°æ®æ”¶é›†å™¨')
    parser.add_argument('--num_scenes', type=int, default=10, help='æ”¶é›†çš„åœºæ™¯æ•°é‡')
    parser.add_argument('--num_objects', type=int, nargs=2, default=[2, 4], help='ç‰©ä½“æ•°é‡èŒƒå›´ [min, max]')
    parser.add_argument('--max_attempts', type=int, default=25, help='æ¯åœºæ™¯æœ€å¤§æŠ“å–å°è¯•æ•°')
    parser.add_argument('--data_dir', type=str, default='data/affordance_v5', help='æ•°æ®ä¿å­˜ç›®å½•')
    parser.add_argument('--angles', type=int, default=8, help='ç¦»æ•£æŠ“å–è§’åº¦æ•°é‡')
    parser.add_argument('--gui', action='store_true', help='æ˜¾ç¤ºGUI')
    
    args = parser.parse_args()
    
    # è¿æ¥PyBullet
    if args.gui:
        p.connect(p.GUI)
    else:
        p.connect(p.DIRECT)
    
    try:
        # åˆ›å»ºæ”¶é›†å™¨
        collector = AutoAffordanceCollector(
            data_dir=args.data_dir,
            num_angles=args.angles
        )
        
        # æ”¶é›†æ•°æ®
        success = collector.collect_dataset(
            num_scenes=args.num_scenes,
            num_objects_range=tuple(args.num_objects),
            max_attempts_per_scene=args.max_attempts
        )
        
        if success:
            print("âœ… æ•°æ®æ”¶é›†æˆåŠŸ!")
        else:
            print("âŒ æ•°æ®æ”¶é›†å¤±è´¥!")
    
    finally:
        p.disconnect()

if __name__ == "__main__":
    main()